{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 7 Computer Vision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFnFX3ZY85r1",
        "colab_type": "text"
      },
      "source": [
        "In this module we will learn about basics of neurons and more specifically perceptrons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I2BBhoac11u",
        "colab_type": "text"
      },
      "source": [
        "Perceptron is basically like a neuron that provides classfied outcomes for computing!\n",
        "\n",
        "![alt text](https://miro.medium.com/max/645/0*LJBO8UbtzK_SKMog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_M411qWeINk",
        "colab_type": "text"
      },
      "source": [
        "The input provided as values for X and W(weights) were only 0 & 1 but in real life problems there are a varied range of inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkqgBMqCd7XT",
        "colab_type": "text"
      },
      "source": [
        "Z as defined earlier was equal to Z = ΣW*X\n",
        "Taking Θ as threshold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "IF:\n",
        "\n",
        "    Z >= Θ  => function is activated => output = 1\n",
        "    Z < Θ  => function is activated => output = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQdX8wGiJ2T",
        "colab_type": "text"
      },
      "source": [
        "Taking  Θ to left hand side of the equation we get:\n",
        "\n",
        "Z - Θ <  0\n",
        "\n",
        "Z - Θ >= 0\n",
        "\n",
        "let's take this -Θ as a constant 'b' .This would be termed as Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v98FbuYnjES0",
        "colab_type": "text"
      },
      "source": [
        "So now our formulae becomes Z = ΣW*X + b \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1kAa0UVjLXD2qL0Ztg4MpXhKpVt0o3Kil)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2bHKbPSlBgo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ9jpXrNjiI6",
        "colab_type": "text"
      },
      "source": [
        "Moving on further we will see the process step by step through the diagram![](https://drive.google.com/uc?export=view&id=1B78wHWb9GSdsW-Xgqk0FFov7rwHeGKHL)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NCBWDewkB_y",
        "colab_type": "text"
      },
      "source": [
        "providing in the inputs X0 and X1 then randomly generating weights to calculate value of Z,then this value of Z is passed onto an **Activation Function**.\n",
        "The activation function of a node defines the output of that node given an input or set of inputs.We have used sigmoid as our activation function because it gives us a continous set of values as our output.Any other linear function would have provided some discrete values therefore here activation functions come into play.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1p_uT1ZWGbh8HyUG65dN-w2ZwxD6w9uo1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x6Iw0XqvkVC",
        "colab_type": "text"
      },
      "source": [
        "we do have some other activations functions such as\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1D4676YnOhkPej7f-nrnfQ4r3MIZnkzjk)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1ar2JrRZUNF3LYrP5l-qf8eWca9pImfG3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMT4MxpFvQEH",
        "colab_type": "text"
      },
      "source": [
        "moving on we have described our loss function as y-y_hat .\n",
        "Some other loss functions that are used are:\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1OOHv3IA--YKTfyKl0RPQTY6sdSyrdJMj)\n",
        "![](https://drive.google.com/uc?export=view&id=1yqKu2czC4bcdvNI-H7fbKzfey5H9bs_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svNXhgsBwetI",
        "colab_type": "text"
      },
      "source": [
        "The loss would be positive or negative depending their values.\n",
        "\n",
        "\n",
        "The process completed till now is termed as **forward paas**.Now the process of **Back Propagation** begins.\n",
        "\n",
        "Backpropagation, short for \"backward propagation of errors,\" is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ4GH4gFxhLk",
        "colab_type": "text"
      },
      "source": [
        "The Calculated Gradient(G) is then passed which gets multiplied with Learning Rate(α). So now the expression becomes equal to α*G .Now we subtract this from our initial Weigths i.e W0 & W1 we get:\n",
        "\n",
        " W0 - αG\n",
        "\n",
        " W1 - αG "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV7Cq0EjyY6X",
        "colab_type": "text"
      },
      "source": [
        "Finally these updated paramteres are passed onto the intial weigth matrix and this process again repeats as many times equal to our number of **epochs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E2XGQksywec",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}